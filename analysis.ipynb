{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyzeDataset(path, timeColumn = 'SubmitTime', delimiter = ','):\n",
    "\n",
    "    datasetname = path.split('/')[-1].split('.')[0]\n",
    "\n",
    "    #Lambda function to convert seconds from 1970 to timestamp\n",
    "    convert_to_timestamp = lambda x: pd.to_datetime(x, unit='s')\n",
    "\n",
    "    # Read the dataset into a dataframe and set the timestamp as the index.\n",
    "    dataset = pd.read_csv(path, parse_dates=[timeColumn], date_parser=convert_to_timestamp, delimiter=delimiter)\n",
    "\n",
    "    # Print the number of rows and columns in the dataframe.\n",
    "    print(\"Dataset Shape:\")\n",
    "    print(dataset.shape)\n",
    "\n",
    "    # Print the number of missing values in dataframe.\n",
    "    print(\"Number of missing values:\")\n",
    "    print(dataset.isnull().sum().sum())\n",
    "\n",
    "    #Print the names of the columns in the dataframe.\n",
    "    print(\"Column Names:\")\n",
    "    print(dataset.columns)\n",
    "\n",
    "    # tex row\n",
    "    jobsInMillions = round(dataset.shape[0] / 1000000, 2)\n",
    "    submitTimesInYears = round((dataset[timeColumn].max() - dataset[timeColumn].min()).days / 365, 2)\n",
    "    print(\"Latex Row:\")\n",
    "    print(f\" \\hline \\n {datasetname} & {jobsInMillions} M & {submitTimesInYears} yrs & \\\\\\\\\")\n",
    "\n",
    "    \n",
    "\n",
    "    \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/rz/x38ry1m901jcjct47ydtrgph0000gn/T/ipykernel_19413/3475230426.py:9: DtypeWarning: Columns (19) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  dataset = pd.read_csv(path, index_col=0, parse_dates=[timeColumn], date_parser=convert_to_timestamp)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Shape:\n",
      "(1124772, 28)\n",
      "Number of missing values:\n",
      "0\n",
      "Column Names:\n",
      "Index(['SubmitTime', 'WaitTime', 'RunTime', 'NProc', 'UsedCPUTime',\n",
      "       'UsedMemory', 'ReqNProcs', 'ReqTime', 'ReqMemory', 'Status', 'UserID',\n",
      "       'GroupID', 'ExecutableID', 'QueueID', 'PartitionID', 'OrigSiteID',\n",
      "       'LastRunSiteID', 'JobStructure', 'JobStructureParams', 'UsedNetwork',\n",
      "       'UsedLocalDiskSpace', 'UsedResources', 'ReqPlatform', 'ReqNetwork',\n",
      "       'ReqLocalDiskSpace', 'ReqResources', 'VOID', 'ProjectID'],\n",
      "      dtype='object')\n",
      "Latex Row:\n",
      " \\hline \n",
      " das2 & 1.12 M & 1.8 yrs & \\\\\n"
     ]
    }
   ],
   "source": [
    "analyzeDataset('./datasets/das2.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Shape:\n",
      "(1020195, 28)\n",
      "Number of missing values:\n",
      "0\n",
      "Column Names:\n",
      "Index(['SubmitTime', 'WaitTime', 'RunTime', 'NProc', 'UsedCPUTime',\n",
      "       'UsedMemory', 'ReqNProcs', 'ReqTime', 'ReqMemory', 'Status', 'UserID',\n",
      "       'GroupID', 'ExecutableID', 'QueueID', 'PartitionID', 'OrigSiteID',\n",
      "       'LastRunSiteID', 'JobStructure', 'JobStructureParams', 'UsedNetwork',\n",
      "       'UsedLocalDiskSpace', 'UsedResources', 'ReqPlatform', 'ReqNetwork',\n",
      "       'ReqLocalDiskSpace', 'ReqResources', 'VOID', 'ProjectID'],\n",
      "      dtype='object')\n",
      "Timeframe:\n",
      "920 days 05:16:15\n",
      "Latex Row:\n",
      " \\hline \n",
      " grid5000 & 1.02 M & 2.52 yrs & \\\\\n"
     ]
    }
   ],
   "source": [
    "analyzeDataset('./datasets/grid5000.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Shape:\n",
      "(781370, 28)\n",
      "Number of missing values:\n",
      "0\n",
      "Column Names:\n",
      "Index(['SubmitTime', 'WaitTime', 'RunTime', 'NProc', 'UsedCPUTime',\n",
      "       'UsedMemory', 'ReqNProcs', 'ReqTime', 'ReqMemory', 'Status', 'UserID',\n",
      "       'GroupID', 'ExecutableID', 'QueueID', 'PartitionID', 'OrigSiteID',\n",
      "       'LastRunSiteID', 'JobStructure', 'JobStructureParams', 'UsedNetwork',\n",
      "       'UsedLocalDiskSpace', 'UsedResources', 'ReqPlatform', 'ReqNetwork',\n",
      "       'ReqLocalDiskSpace', 'ReqResources', 'VOID', 'ProjectID'],\n",
      "      dtype='object')\n",
      "Timeframe:\n",
      "1151 days 06:47:06\n",
      "Latex Row:\n",
      " \\hline \n",
      " nordugrid & 0.78 M & 3.15 yrs & \\\\\n"
     ]
    }
   ],
   "source": [
    "analyzeDataset('./datasets/nordugrid.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Shape:\n",
      "(404176, 28)\n",
      "Number of missing values:\n",
      "0\n",
      "Column Names:\n",
      "Index(['SubmitTime', 'WaitTime', 'RunTime', 'NProc', 'UsedCPUTime',\n",
      "       'UsedMemory', 'ReqNProcs', 'ReqTime', 'ReqMemory', 'Status', 'UserID',\n",
      "       'GroupID', 'ExecutableID', 'QueueID', 'PartitionID', 'OrigSiteID',\n",
      "       'LastRunSiteID', 'JobStructure', 'JobStructureParams', 'UsedNetwork',\n",
      "       'UsedLocalDiskSpace', 'UsedResources', 'ReqPlatform', 'ReqNetwork',\n",
      "       'ReqLocalDiskSpace', 'ReqResources', 'VOID', 'ProjectID'],\n",
      "      dtype='object')\n",
      "Timeframe:\n",
      "364 days 23:56:06\n",
      "Latex Row:\n",
      " \\hline \n",
      " auvergrid & 0.4 M & 1.0 yrs & \\\\\n"
     ]
    }
   ],
   "source": [
    "analyzeDataset('./datasets/auvergrid.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Shape:\n",
      "(1195242, 28)\n",
      "Number of missing values:\n",
      "0\n",
      "Column Names:\n",
      "Index(['SubmitTime', 'WaitTime', 'RunTime', 'NProc', 'UsedCPUTime',\n",
      "       'UsedMemory', 'ReqNProcs', 'ReqTime', 'ReqMemory', 'Status', 'UserID',\n",
      "       'GroupID', 'ExecutableID', 'QueueID', 'PartitionID', 'OrigSiteID',\n",
      "       'LastRunSiteID', 'JobStructure', 'JobStructureParams', 'UsedNetwork',\n",
      "       'UsedLocalDiskSpace', 'UsedResources', 'ReqPlatform', 'ReqNetwork',\n",
      "       'ReqLocalDiskSpace', 'ReqResources', 'VOID', 'ProjectID'],\n",
      "      dtype='object')\n",
      "Timeframe:\n",
      "390 days 22:45:48\n",
      "Latex Row:\n",
      " \\hline \n",
      " sharcnet & 1.2 M & 1.07 yrs & \\\\\n"
     ]
    }
   ],
   "source": [
    "analyzeDataset('./datasets/sharcnet.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Shape:\n",
      "(188041, 28)\n",
      "Number of missing values:\n",
      "0\n",
      "Column Names:\n",
      "Index(['SubmitTime', 'WaitTime', 'RunTime', 'NProc', 'UsedCPUTime',\n",
      "       'UsedMemory', 'ReqNProcs', 'ReqTime', 'ReqMemory', 'Status', 'UserID',\n",
      "       'GroupID', 'ExecutableID', 'QueueID', 'PartitionID', 'OrigSiteID',\n",
      "       'LastRunSiteID', 'JobStructure', 'JobStructureParams', 'UsedNetwork',\n",
      "       'UsedLocalDiskSpace', 'UsedResources', 'ReqPlatform', 'ReqNetwork',\n",
      "       'ReqLocalDiskSpace', 'ReqResources', 'VOID', 'ProjectID'],\n",
      "      dtype='object')\n",
      "Timeframe:\n",
      "10 days 23:59:52\n",
      "Latex Row:\n",
      " \\hline \n",
      " lcg & 0.19 M & 0.03 yrs & \\\\\n"
     ]
    }
   ],
   "source": [
    "analyzeDataset('./datasets/lcg.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge 500 csv's into one\n",
    "def mergeCSVs(path):\n",
    "    csvList = []\n",
    "    for csv in glob.glob(f\"./datasets/{path}/*/*.csv\"):\n",
    "        pd.read_csv(csv, delimiter=';\\t')\n",
    "        csvList.append(csv)\n",
    "    df = pd.concat(csvList)\n",
    "    df.rename(columns={'Timestamp [ms]': 'SubmitTime'}, inplace=True)\n",
    "    df.to_csv( \"./datasets/{path}.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Timestamp [ms];\\tCPU cores;\\tCPU capacity provisioned [MHZ];\\tCPU usage [MHZ];\\tCPU usage [%];\\tMemory capacity provisioned [KB];\\tMemory usage [KB];\\tDisk read throughput [KB/s];\\tDisk write throughput [KB/s];\\tNetwork received throughput [KB/s];\\tNetwork transmitted throughput [KB/s]'], dtype='object')"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mergeCSVs('fastStorage')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/rz/x38ry1m901jcjct47ydtrgph0000gn/T/ipykernel_19413/2553795356.py:9: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  dataset = pd.read_csv(path, parse_dates=[timeColumn], date_parser=convert_to_timestamp, delimiter=delimiter)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/rz/x38ry1m901jcjct47ydtrgph0000gn/T/ipykernel_19413/1791844232.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0manalyzeDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'./datasets/fastStorage.csv'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Timestamp [ms]'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m';\\t'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/var/folders/rz/x38ry1m901jcjct47ydtrgph0000gn/T/ipykernel_19413/2553795356.py\u001b[0m in \u001b[0;36manalyzeDataset\u001b[0;34m(path, timeColumn, delimiter)\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;31m# Read the dataset into a dataframe and set the timestamp as the index.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparse_dates\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtimeColumn\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdate_parser\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconvert_to_timestamp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdelimiter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdelimiter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0;31m# Print the number of rows and columns in the dataframe.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    209\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m                     \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnew_arg_name\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_arg_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 211\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    212\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    329\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfind_stack_level\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m                 )\n\u001b[0;32m--> 331\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    332\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    333\u001b[0m         \u001b[0;31m# error: \"Callable[[VarArg(Any), KwArg(Any)], Any]\" has no\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    948\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    949\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 950\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    951\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    952\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    609\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    610\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mparser\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 611\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mparser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    612\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    613\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m   1776\u001b[0m                     \u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1777\u001b[0m                     \u001b[0mcol_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1778\u001b[0;31m                 \u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m  \u001b[0;31m# type: ignore[attr-defined]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1779\u001b[0m                     \u001b[0mnrows\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1780\u001b[0m                 )\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/io/parsers/python_parser.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, rows)\u001b[0m\n\u001b[1;32m    283\u001b[0m         \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_exclude_implicit_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0malldata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    284\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 285\u001b[0;31m         \u001b[0mconv_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_convert_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    286\u001b[0m         \u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconv_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_date_conversions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconv_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    287\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/io/parsers/python_parser.py\u001b[0m in \u001b[0;36m_convert_data\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m    347\u001b[0m             \u001b[0mclean_na_fvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mna_fvalues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    348\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 349\u001b[0;31m         return self._convert_to_ndarrays(\n\u001b[0m\u001b[1;32m    350\u001b[0m             \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    351\u001b[0m             \u001b[0mclean_na_values\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/io/parsers/base_parser.py\u001b[0m in \u001b[0;36m_convert_to_ndarrays\u001b[0;34m(self, dct, na_values, na_fvalues, verbose, converters, dtypes)\u001b[0m\n\u001b[1;32m    584\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    585\u001b[0m                 \u001b[0;31m# general type inference and conversion\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 586\u001b[0;31m                 cvals, na_count = self._infer_types(\n\u001b[0m\u001b[1;32m    587\u001b[0m                     \u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcol_na_values\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0mcol_na_fvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtry_num_bool\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    588\u001b[0m                 )\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/io/parsers/base_parser.py\u001b[0m in \u001b[0;36m_infer_types\u001b[0;34m(self, values, na_values, try_num_bool)\u001b[0m\n\u001b[1;32m    710\u001b[0m             \u001b[0;31m# exclude e.g DatetimeIndex here\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    711\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 712\u001b[0;31m                 \u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmaybe_convert_numeric\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mna_values\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    713\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mValueError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    714\u001b[0m                 \u001b[0;31m# e.g. encountering datetime string gets ValueError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "analyzeDataset('./datasets/fastStorage.csv', 'Timestamp [ms]', ';\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1250"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(glob.glob(\"./datasets/fastStorage/*/*.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
